{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "785d7b38",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "48edd648",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as mp\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pyESN import ESN\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import itertools\n",
    "from collections import Counter\n",
    "import mlflow\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1877aa48",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3e39ea89",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_excel(\"/workspaces/Time-series-prediction-for-pollution-data/air_pollution_data.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "795d4d4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>date</th>\n",
       "      <th>aqi</th>\n",
       "      <th>co</th>\n",
       "      <th>no</th>\n",
       "      <th>no2</th>\n",
       "      <th>o3</th>\n",
       "      <th>so2</th>\n",
       "      <th>pm2_5</th>\n",
       "      <th>pm10</th>\n",
       "      <th>nh3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>2020-11-30</td>\n",
       "      <td>5</td>\n",
       "      <td>520.71</td>\n",
       "      <td>2.38</td>\n",
       "      <td>16.28</td>\n",
       "      <td>130.18</td>\n",
       "      <td>47.68</td>\n",
       "      <td>65.96</td>\n",
       "      <td>72.13</td>\n",
       "      <td>8.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>2020-12-01</td>\n",
       "      <td>5</td>\n",
       "      <td>1682.28</td>\n",
       "      <td>7.71</td>\n",
       "      <td>54.84</td>\n",
       "      <td>0.73</td>\n",
       "      <td>21.70</td>\n",
       "      <td>120.95</td>\n",
       "      <td>154.53</td>\n",
       "      <td>27.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>2020-12-02</td>\n",
       "      <td>5</td>\n",
       "      <td>1815.80</td>\n",
       "      <td>16.54</td>\n",
       "      <td>49.35</td>\n",
       "      <td>0.17</td>\n",
       "      <td>23.84</td>\n",
       "      <td>133.47</td>\n",
       "      <td>172.63</td>\n",
       "      <td>28.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>2020-12-03</td>\n",
       "      <td>5</td>\n",
       "      <td>2296.45</td>\n",
       "      <td>41.57</td>\n",
       "      <td>40.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>35.76</td>\n",
       "      <td>150.37</td>\n",
       "      <td>202.15</td>\n",
       "      <td>36.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>2020-12-04</td>\n",
       "      <td>5</td>\n",
       "      <td>2189.64</td>\n",
       "      <td>23.92</td>\n",
       "      <td>58.95</td>\n",
       "      <td>0.02</td>\n",
       "      <td>28.13</td>\n",
       "      <td>160.79</td>\n",
       "      <td>205.80</td>\n",
       "      <td>40.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23499</th>\n",
       "      <td>Visakhapatnam</td>\n",
       "      <td>2023-05-21</td>\n",
       "      <td>3</td>\n",
       "      <td>353.81</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.08</td>\n",
       "      <td>100.14</td>\n",
       "      <td>4.11</td>\n",
       "      <td>37.53</td>\n",
       "      <td>47.09</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23500</th>\n",
       "      <td>Visakhapatnam</td>\n",
       "      <td>2023-05-22</td>\n",
       "      <td>3</td>\n",
       "      <td>380.52</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.77</td>\n",
       "      <td>82.97</td>\n",
       "      <td>5.07</td>\n",
       "      <td>32.17</td>\n",
       "      <td>43.44</td>\n",
       "      <td>1.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23501</th>\n",
       "      <td>Visakhapatnam</td>\n",
       "      <td>2023-05-23</td>\n",
       "      <td>3</td>\n",
       "      <td>390.53</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.28</td>\n",
       "      <td>80.11</td>\n",
       "      <td>5.19</td>\n",
       "      <td>36.01</td>\n",
       "      <td>48.06</td>\n",
       "      <td>1.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23502</th>\n",
       "      <td>Visakhapatnam</td>\n",
       "      <td>2023-05-24</td>\n",
       "      <td>3</td>\n",
       "      <td>300.41</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.36</td>\n",
       "      <td>95.84</td>\n",
       "      <td>2.21</td>\n",
       "      <td>30.17</td>\n",
       "      <td>48.89</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23503</th>\n",
       "      <td>Visakhapatnam</td>\n",
       "      <td>2023-05-25</td>\n",
       "      <td>4</td>\n",
       "      <td>427.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>88.69</td>\n",
       "      <td>10.73</td>\n",
       "      <td>52.36</td>\n",
       "      <td>61.41</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23504 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                city       date  aqi       co  ...    so2   pm2_5    pm10    nh3\n",
       "0          Ahmedabad 2020-11-30    5   520.71  ...  47.68   65.96   72.13   8.36\n",
       "1          Ahmedabad 2020-12-01    5  1682.28  ...  21.70  120.95  154.53  27.36\n",
       "2          Ahmedabad 2020-12-02    5  1815.80  ...  23.84  133.47  172.63  28.12\n",
       "3          Ahmedabad 2020-12-03    5  2296.45  ...  35.76  150.37  202.15  36.48\n",
       "4          Ahmedabad 2020-12-04    5  2189.64  ...  28.13  160.79  205.80  40.53\n",
       "...              ...        ...  ...      ...  ...    ...     ...     ...    ...\n",
       "23499  Visakhapatnam 2023-05-21    3   353.81  ...   4.11   37.53   47.09   0.08\n",
       "23500  Visakhapatnam 2023-05-22    3   380.52  ...   5.07   32.17   43.44   1.74\n",
       "23501  Visakhapatnam 2023-05-23    3   390.53  ...   5.19   36.01   48.06   1.20\n",
       "23502  Visakhapatnam 2023-05-24    3   300.41  ...   2.21   30.17   48.89   0.00\n",
       "23503  Visakhapatnam 2023-05-25    4   427.25  ...  10.73   52.36   61.41   0.20\n",
       "\n",
       "[23504 rows x 11 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977e4284",
   "metadata": {},
   "source": [
    "## sorting cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "12006896",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_city = data[\"city\"].unique()\n",
    "\n",
    "# Sorting cities alphabetically\n",
    "unique_city= sorted(unique_city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "21fb92cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dict to hold city wise data\n",
    "city_df = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2275135f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for city in data[\"city\"].unique():\n",
    "    city_df[city] = data[data[\"city\"] == city].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8094f563",
   "metadata": {},
   "outputs": [],
   "source": [
    "ahmedabad_df=data[data[\"city\"] == \"Ahmedabad\"].copy()\n",
    "\n",
    "x = ahmedabad_df.drop(columns=[\"city\", \"aqi\",\"date\"])\n",
    "y = ahmedabad_df[\"aqi\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5a5c978c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      5\n",
       "1      5\n",
       "2      5\n",
       "3      5\n",
       "4      5\n",
       "      ..\n",
       "899    3\n",
       "900    3\n",
       "901    3\n",
       "902    3\n",
       "903    3\n",
       "Name: aqi, Length: 904, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54afb25",
   "metadata": {},
   "source": [
    "## Scaling \n",
    "we have already used the same scaler in pollutant model training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "02b49eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/workspaces/Time-series-prediction-for-pollution-data/models/minmaxscaling.pkl\", \"rb\") as f:\n",
    "    scaler = pickle.load(f)\n",
    "\n",
    "# Apply same transformation as in previous notebook\n",
    "x_scaled = scaler.transform(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ad1a44",
   "metadata": {},
   "source": [
    "# data prep for model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "33e3adb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "features=ahmedabad_df.columns\n",
    "features=[f for f in features if f != \"aqi\" and f!= \"date\" and f!=\"city\"] #all except aqi column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4abebb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "lookback = 5\n",
    "forecast_horizon = 20 # in previous notebook we have looked ahead 20 timestamps\n",
    "steps_needed = 6      # will predict for 6 AQI heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f45e2f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_input = [x_scaled[i+lookback-1, :] for i in range(len(x_scaled) - lookback - forecast_horizon)]\n",
    "X_input = np.array(X_input)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "66860f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_feature_steps = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "848c45d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in features:\n",
    "    # Loading model\n",
    "    with open(f\"/workspaces/Time-series-prediction-for-pollution-data/models/{feature}_esn_model.pkl\", \"rb\") as f:\n",
    "        esn = pickle.load(f)\n",
    "    \n",
    "    # Predict for entire dataset\n",
    "    feature_pred = esn.predict(X_input, len(X_input))  # shape: (samples, forecast_horizon)\n",
    "    \n",
    "    # Keep only first 6 steps\n",
    "    predicted_feature_steps[feature] = feature_pred[:, :steps_needed]  # (samples, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0994cd",
   "metadata": {},
   "source": [
    "input variable final (X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3880149c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []  #final feature space initialised\n",
    "\n",
    "for i in range(len(X_input)):\n",
    "    one_sample = []\n",
    "    for step in range(steps_needed):  # t+1 to t+6 6 steps ahead in time for AQI prediction\n",
    "        for feature in features:\n",
    "            one_sample.append(predicted_feature_steps[feature][i, step])\n",
    "    X.append(one_sample)\n",
    "\n",
    "X = np.array(X)  # shape: (samples, 6 Ã— no. of features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "22ac9d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "aqi_values = y.values  # categorical AQI values, like 0â€“5, unscaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52ca096",
   "metadata": {},
   "source": [
    "preparing target variable (Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "88307ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = []\n",
    "\n",
    "for i in range(len(x_scaled) - lookback - forecast_horizon):\n",
    "    future_aqi = aqi_values[i+lookback:i+lookback+steps_needed]\n",
    "    Y.append(future_aqi)\n",
    "\n",
    "Y = np.array(Y,dtype=int)  # shape: (samples, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6d84143a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 5, 5, 5, 5, 5],\n",
       "       [5, 5, 5, 5, 5, 5],\n",
       "       [5, 5, 5, 5, 5, 5],\n",
       "       ...,\n",
       "       [4, 5, 2, 3, 3, 3],\n",
       "       [5, 2, 3, 3, 3, 3],\n",
       "       [2, 3, 3, 3, 3, 3]], shape=(879, 6))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e14bd3",
   "metadata": {},
   "source": [
    "## post train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dd44bfbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6b72c5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = (y_train - 1).astype(int)\n",
    "y_test = (y_test - 1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "43b4a119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2, 3, 4]), array([ 132,  612,  282,  876, 2316]))\n",
      "(array([0, 1, 2, 3, 4]), array([ 12,  66, 165, 198, 615]))\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(y_train, return_counts=True))\n",
    "print(np.unique(y_test, return_counts=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75e205f",
   "metadata": {},
   "source": [
    "## Handle class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1e82c704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class counts: Counter({np.int64(4): 386, np.int64(3): 146, np.int64(1): 102, np.int64(2): 47, np.int64(0): 22})\n",
      "Class weights: {np.int64(4): 1.8212435233160622, np.int64(3): 4.815068493150685, np.int64(1): 6.892156862745098, np.int64(0): 31.954545454545453, np.int64(2): 14.957446808510639}\n"
     ]
    }
   ],
   "source": [
    "# class frequencies in y_train for t+1\n",
    "class_counts = Counter(y_train[:, 0])\n",
    "print(\"Class counts:\", class_counts)\n",
    "\n",
    "# inverse weights\n",
    "total = sum(class_counts.values())\n",
    "class_weights = {cls: total / count for cls, count in class_counts.items()}\n",
    "print(\"Class weights:\", class_weights)\n",
    "\n",
    "# weight array\n",
    "sample_weights = np.array([class_weights[label] for label in y_train[:, 0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c38598",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54e50ae",
   "metadata": {},
   "source": [
    "mlflow setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bb5ae9d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='/workspaces/Time-series-prediction-for-pollution-data/mlruns/273469853540485859', creation_time=1752752938314, experiment_id='273469853540485859', last_update_time=1752752938314, lifecycle_stage='active', name='AQI_Prediction_XGBoost', tags={}>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(\"/workspaces/Time-series-prediction-for-pollution-data/mlruns\")  \n",
    "mlflow.set_experiment(\"AQI_Prediction_XGBoost\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53f2d72",
   "metadata": {},
   "source": [
    "defining hyper params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "65a081f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparams\n",
    "n_estimators_list = [300, 200]\n",
    "max_depth_list = [4, 6,10]\n",
    "learning_rate_list = [0.05, 0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "43846503",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/17 13:24:51 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\u001b[31m2025/07/17 13:24:54 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged run with est=300, depth=4, lr=0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/17 13:25:11 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\u001b[31m2025/07/17 13:25:14 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged run with est=300, depth=4, lr=0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/17 13:25:50 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\u001b[31m2025/07/17 13:25:53 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged run with est=300, depth=6, lr=0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/17 13:26:16 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\u001b[31m2025/07/17 13:26:18 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged run with est=300, depth=6, lr=0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/17 13:27:04 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\u001b[31m2025/07/17 13:27:06 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged run with est=300, depth=10, lr=0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/17 13:27:34 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\u001b[31m2025/07/17 13:27:36 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged run with est=300, depth=10, lr=0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/17 13:27:51 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\u001b[31m2025/07/17 13:27:53 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged run with est=200, depth=4, lr=0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/17 13:28:06 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\u001b[31m2025/07/17 13:28:08 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged run with est=200, depth=4, lr=0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/17 13:28:36 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\u001b[31m2025/07/17 13:28:39 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged run with est=200, depth=6, lr=0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/17 13:28:58 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\u001b[31m2025/07/17 13:29:00 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged run with est=200, depth=6, lr=0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/17 13:29:43 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\u001b[31m2025/07/17 13:29:46 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged run with est=200, depth=10, lr=0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/17 13:30:10 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\u001b[31m2025/07/17 13:30:13 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged run with est=200, depth=10, lr=0.1\n"
     ]
    }
   ],
   "source": [
    "for n_estimators, max_depth, learning_rate in itertools.product(n_estimators_list, max_depth_list, learning_rate_list):\n",
    "\n",
    "    with mlflow.start_run(run_name=f\"xgb_est{n_estimators}_depth{max_depth}_lr{learning_rate}\"):\n",
    "\n",
    "        # Train the model\n",
    "        base_model = XGBClassifier(n_estimators=n_estimators,\n",
    "                                  max_depth=max_depth,\n",
    "                                  learning_rate=learning_rate,\n",
    "                                  objective=\"multi:softprob\",\n",
    "                                  num_class=5  # 5 AQI categories\n",
    "                                  )\n",
    "        model = MultiOutputClassifier(base_model)\n",
    "        model.fit(x_train, y_train,sample_weight=sample_weights)\n",
    "\n",
    "        # Predict\n",
    "        y_pred = model.predict(x_test)\n",
    "\n",
    "        # Logging hyperparameters\n",
    "        mlflow.log_param(\"n_estimators\", n_estimators)\n",
    "        mlflow.log_param(\"max_depth\", max_depth)\n",
    "        mlflow.log_param(\"learning_rate\", learning_rate)\n",
    "\n",
    "        # Evaluate and log metrics for each step \n",
    "        for step in range(Y.shape[1]):\n",
    "            acc = accuracy_score(y_test[:, step], y_pred[:, step])\n",
    "            mlflow.log_metric(f\"accuracy_t{step+1}\", acc)    \n",
    "            report = classification_report(y_test[:, step], y_pred[:, step], output_dict=True,zero_division=0)\n",
    "            mlflow.log_metric(f\"f1_macro_t{step+1}\", report[\"macro avg\"][\"f1-score\"])\n",
    "            mlflow.log_metric(f\"recall_macro_t{step+1}\", report[\"macro avg\"][\"recall\"])   \n",
    "  \n",
    "\n",
    "        # Save model\n",
    "        mlflow.sklearn.log_model(model, artifact_path=\"xgboostmodel\")\n",
    "\n",
    "        print(f\"Logged run with est={n_estimators}, depth={max_depth}, lr={learning_rate}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "be04a68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_id = mlflow.get_experiment_by_name(\"AQI_Prediction_XGBoost\").experiment_id\n",
    "df_mlflow = mlflow.search_runs(experiment_ids=[experiment_id])\n",
    "df_mlflow.to_csv(\"/workspaces/Time-series-prediction-for-pollution-data/logs/mlflow_summary_baseline.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "dffdbd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_run = df_mlflow.sort_values(\"metrics.f1_macro_t2\", ascending=False).iloc[0]\n",
    "best_run.to_frame().to_csv(\"/workspaces/Time-series-prediction-for-pollution-data/logs/best_run_baseline.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
